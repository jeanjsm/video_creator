# -*- coding: utf-8 -*-
"""
app/application/services/video_creation_service.py
Servi칞o de cria칞칚o de v칤deo atualizado com suporte a legendas
"""

from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

from ...domain.models.timeline import Timeline, Track, Clip, RenderSettings
from ...domain.models.effects import EffectRef
from ...domain.models.subtitle import SubtitleStyle
from ...rendering.graph_builder import GraphBuilder
from ...rendering.cli_builder import CliBuilder
from ...rendering.runner import Runner
from ...rendering.batch_renderer import BatchRenderer
from ...rendering.simple_renderer import SimpleRenderer
from ...infra.media_io import MediaIO
from ...infra.logging import get_logger
from ...infra.paths import ffmpeg_bin
from .transcription_service import TranscriptionService
from fractions import Fraction


@dataclass
class VideoCreationRequest:
    """Requisi칞칚o para cria칞칚o de v칤deo com suporte a legendas"""

    audio_path: Path
    images: List[Path]
    output_path: Path
    segment_duration: float = 3.0
    transition: Optional[str] = None
    encoder: str = "libx264"
    background_music_path: Optional[Path] = None
    background_music_volume: float = 0.2
    logo_path: Optional[Path] = None
    logo_position: str = "top_left"
    logo_opacity: float = 1.0
    logo_scale: float = 0.15
    overlays: Optional[List[Dict[str, Any]]] = None
    overlays_chromakey: Optional[List[Dict[str, Any]]] = None
    cover_path: Optional[Path] = None
    cover_opacity: float = 1.0
    cover_size: float = 1.0
    cover_position: str = "center"

    # Configura칞칫es de legenda
    enable_subtitles: bool = False
    subtitle_style: Optional[SubtitleStyle] = None
    vosk_model_path: Optional[Path] = None
    subtitle_confidence_threshold: float = 0.5
    subtitle_max_duration: float = 4.0


class VideoCreationService:
    """Servi칞o para cria칞칚o de v칤deos seguindo Clean Architecture"""

    def __init__(self):
        self.logger = get_logger("VideoCreationService")
        self.media_io = MediaIO()
        self.simple_renderer = SimpleRenderer()
        self.transcription_service = None

    def create_video(self, request: VideoCreationRequest) -> Path:
        """Cria v칤deo a partir da requisi칞칚o"""
        self.logger.info(
            "Iniciando cria칞칚o de v칤deo: sa칤da=%s, imagens=%d, 치udio=%s, legendas=%s",
            request.output_path,
            len(request.images),
            request.audio_path,
            request.enable_subtitles,
        )

        # 1. Inicializar servi칞o de transcri칞칚o se necess치rio
        if request.enable_subtitles:
            self._init_transcription_service(request.vosk_model_path)

        # 2. Construir timeline a partir dos inputs
        timeline = self._build_timeline(request)

        # 3. Construir render settings
        settings = self._build_render_settings(request)

        # 4. Renderizar usando SimpleRenderer (passar overlays_chromakey)
        result_path = self.simple_renderer.render(
            timeline, settings, request.output_path, overlays_chromakey=request.overlays_chromakey
        )

        self.logger.info("V칤deo criado com sucesso: %s", result_path)
        return result_path

    def _init_transcription_service(self, model_path: Optional[Path]):
        """Inicializa o servi칞o de transcri칞칚o"""
        # Usar ConfigAwareTranscriptionService que l칡 config.json
        from .config_aware_transcription_service import ConfigAwareTranscriptionService
        self.transcription_service = ConfigAwareTranscriptionService(model_path)

        if not self.transcription_service.is_available():
            self.logger.warning(
                "Servi칞o de transcri칞칚o n칚o dispon칤vel. "
                "Verifique se o Vosk est치 instalado e o modelo est치 presente."
            )

    def _build_timeline(self, request: VideoCreationRequest) -> Timeline:
        """Constr칩i timeline a partir da requisi칞칚o"""
        audio_duration = self.media_io.get_audio_duration(request.audio_path)

        # Criar clips de v칤deo
        video_clips = []
        current_time = 0

        for i, image_path in enumerate(request.images):
            if audio_duration and current_time >= audio_duration:
                break

            clip_effects = self._get_image_effects(request, i)

            # Adicionar efeito de legenda no primeiro clip se habilitado
            if request.enable_subtitles and i == 0:
                subtitle_effect = self._create_subtitle_effect(request)
                if subtitle_effect:
                    clip_effects.append(subtitle_effect)

            # Adicionar chromas do config.json no primeiro clip
            if i == 0:
                chroma_effects = self._get_chroma_effects_from_config()
                clip_effects.extend(chroma_effects)

            clip = Clip(
                id=f"img_{i}",
                media_path=image_path,
                in_ms=0,
                out_ms=int(request.segment_duration * 1000),
                start_ms=int(current_time * 1000),
                effects=clip_effects,
            )
            video_clips.append(clip)
            current_time += request.segment_duration

        # Criar track de v칤deo
        video_track = Track(id="video_main", kind="video", clips=video_clips)

        # Criar clips de 치udio
        audio_clips = []
        if request.audio_path:
            audio_clip = Clip(
                id="narration",
                media_path=request.audio_path,
                in_ms=0,
                out_ms=int(audio_duration * 1000),
                start_ms=0,
            )
            audio_clips.append(audio_clip)

        if request.background_music_path:
            bg_clip = Clip(
                id="background_music",
                media_path=request.background_music_path,
                in_ms=0,
                out_ms=int(audio_duration * 1000),
                start_ms=0,
                effects=[
                    EffectRef(
                        name="volume",
                        params={"volume": request.background_music_volume},
                    )
                ],
            )
            audio_clips.append(bg_clip)

        # Criar track de 치udio
        audio_track = Track(id="audio_main", kind="audio", clips=audio_clips)

        return Timeline(
            fps=Fraction(30, 1),
            resolution=(1280, 720),
            video=[video_track],
            audio=[audio_track],
        )

    def _create_subtitle_effect(self, request: VideoCreationRequest) -> Optional[EffectRef]:
        """Cria efeito de legenda baseado na transcri칞칚o do 치udio"""
        if not self.transcription_service:
            self.logger.warning("Servi칞o de transcri칞칚o n칚o foi inicializado")
            return None

        if not self.transcription_service.is_available():
            self.logger.warning("Servi칞o de transcri칞칚o n칚o dispon칤vel para legendas")
            return None

        try:
            # Transcrever 치udio
            self.logger.info("Transcrevendo 치udio para legendas...")

            # Usar transcribe_with_config se dispon칤vel (ConfigAwareTranscriptionService)
            if hasattr(self.transcription_service, 'transcribe_with_config'):
                transcription, style = self.transcription_service.transcribe_with_config(
                    request.audio_path,
                    override_params={
                        "confidence_threshold": request.subtitle_confidence_threshold,
                        "max_segment_duration": request.subtitle_max_duration
                    }
                )
                # Usar estilo do request se especificado, sen칚o usar do config
                final_style = request.subtitle_style or style
            else:
                # Fallback para TranscriptionService b치sico
                final_style = request.subtitle_style or SubtitleStyle()
                transcription = self.transcription_service.transcribe_audio(
                    request.audio_path,
                    confidence_threshold=request.subtitle_confidence_threshold,
                    max_segment_duration=request.subtitle_max_duration,
                    max_chars_per_line=final_style.max_chars_per_line,
                    max_words_per_line=final_style.max_words_per_line
                )

            if not transcription.segments:
                self.logger.warning("Nenhum segmento de fala encontrado para legendas")
                return None

            self.logger.info(f"Transcri칞칚o conclu칤da: {len(transcription.segments)} segmentos")

            # Salvar arquivo SRT para an치lise
            self._save_subtitle_file(transcription, request.output_path)

            # Criar efeito de legenda
            return EffectRef(
                name="subtitle",
                params={
                    "segments": transcription.segments,
                    "style": final_style,
                },
                target="video"
            )

        except Exception as e:
            self.logger.error(f"Erro na transcri칞칚o para legendas: {e}")
            return None

    def _save_subtitle_file(self, transcription, output_path: Path) -> None:
        """Salva arquivo SRT das legendas no mesmo diret칩rio do v칤deo"""
        try:
            # Gerar caminho do arquivo SRT baseado no v칤deo de sa칤da
            srt_path = output_path.with_suffix('.srt')

            # Salvar arquivo SRT
            transcription.save_as_srt(srt_path)

            self.logger.info(f"Arquivo de legendas salvo: {srt_path}")
            print(f"游늯 Arquivo de legendas salvo: {srt_path}")

        except Exception as e:
            self.logger.error(f"Erro ao salvar arquivo de legendas: {e}")

    def _get_image_effects(
            self, request: VideoCreationRequest, index: int
    ) -> List[EffectRef]:
        """Retorna efeitos para aplicar em uma imagem"""
        effects = []

        # Adicionar transi칞칫es se especificado
        if request.transition and index > 0:
            effects.append(EffectRef(name=request.transition, params={"duration": 1.0}))

        # Adicionar logo se especificado (apenas no primeiro clip para evitar duplica칞칚o)
        if request.logo_path and index == 0:
            effects.append(
                EffectRef(
                    name="logo",
                    params={
                        "path": str(request.logo_path),
                        "position": request.logo_position,
                        "scale": request.logo_scale,
                        "opacity": request.logo_opacity,
                    },
                )
            )

        # Adicionar overlays de v칤deo se especificado (apenas no primeiro clip)
        if request.overlays and index == 0:
            from app.plugins.builtin.effects.overlay import OverlayEffect

            for i, overlay in enumerate(request.overlays):
                overlay_effect = OverlayEffect(
                    {
                        "path": overlay["path"],
                        "opacity": overlay.get("opacidade", 1.0),
                        "position": overlay.get("position", "center"),
                        "scale": overlay.get("scale", 1.0),
                    }
                )
                effects.append(
                    EffectRef(
                        name="overlay",
                        params={
                            "path": overlay_effect.path,
                            "opacity": overlay_effect.opacity,
                            "position": overlay_effect.position,
                            "scale": overlay_effect.scale,
                        },
                    )
                )

        # Adicionar capa se especificado (apenas no primeiro clip)
        if request.cover_path and index == 0:
            effects.append(
                EffectRef(
                    name="cover",
                    params={
                        "path": str(request.cover_path),
                        "position": request.cover_position,
                        "size": request.cover_size,
                        "opacity": request.cover_opacity,
                    },
                )
            )

        return effects

    def _get_chroma_effects_from_config(self) -> List[EffectRef]:
        """Obt칠m efeitos de chroma do config.json"""
        try:
            from ...infra.config import get_config
            config = get_config()
            chromas = config.get("chromas", [])

            if not chromas:
                return []

            self.logger.info(f"Encontrados {len(chromas)} chromas no config.json")

            chroma_effects = []
            for i, chroma in enumerate(chromas):
                chroma_path = chroma.get("path")
                if not chroma_path:
                    continue

                # Verificar se arquivo existe
                from pathlib import Path
                if not Path(chroma_path).exists():
                    self.logger.warning(f"Arquivo chroma n칚o encontrado: {chroma_path}")
                    continue

                self.logger.info(f"Adicionando chroma: {chroma_path}")

                # Criar EffectRef para chroma
                chroma_effect = EffectRef(
                    name="chroma_overlay",
                    params={
                        "path": chroma_path,
                        "start": chroma.get("start", 0),
                        "opacity": chroma.get("opacity", 1.0),
                        "tolerance": chroma.get("tolerance", 0.2),
                        "position": chroma.get("position", "bottom_center"),
                        "size": chroma.get("size", 1.0),
                        "duration": chroma.get("duration"),  # Pode ser None
                        "colorkey": chroma.get("colorkey", "0x00FF00"),
                        "colorkey_similarity": chroma.get("colorkey_similarity", 0.35),
                        "colorkey_blend": chroma.get("colorkey_blend", 0.10),
                        "threshold": chroma.get("threshold", 0.03),
                        "ratio": chroma.get("ratio", 8),
                        "attack": chroma.get("attack", 5),
                        "release": chroma.get("release", 300),
                    },
                    target="video"
                )
                chroma_effects.append(chroma_effect)

            return chroma_effects

        except Exception as e:
            self.logger.error(f"Erro ao ler chromas do config.json: {e}")
            return []

    def _build_render_settings(self, request: VideoCreationRequest) -> RenderSettings:
        """Constr칩i configura칞칫es de renderiza칞칚o"""
        return RenderSettings(
            container="mp4",
            vcodec=request.encoder,
            acodec="aac",
            crf=23,
            preset="p5" if "nvenc" in request.encoder else "medium",
            audio_bitrate="192k",
            hwaccel="cuda" if "nvenc" in request.encoder else None,
            ffmpeg_path=ffmpeg_bin(),
        )
